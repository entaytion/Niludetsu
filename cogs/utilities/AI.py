import discord
from discord.ext import commands
from discord import app_commands
from Niludetsu.utils.embed import Embed
from Niludetsu.utils.constants import Emojis
import g4f
import asyncio
from typing import Optional, List, Dict
from enum import Enum

class ProviderCategory(Enum):
    NO_AUTH = "–ë–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"
    OPTIONAL_API = "–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π API –∫–ª—é—á"
    AUTO_COOKIES = "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫—É–∫–∏"
    MANUAL_COOKIES = "–†—É—á–Ω—ã–µ –∫—É–∫–∏"

class AI(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        # –≠–º–æ–¥–∑–∏ –¥–ª—è –ò–ò
        self.AI_EMOJI = "ü§ñ"
        # –°–ª–æ–≤–∞—Ä—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ —Å –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
        self.provider_info: Dict[g4f.Provider, Dict] = {
            g4f.Provider.AIUncensored: {
                "name": "AI Uncensored",
                "auth": ProviderCategory.OPTIONAL_API,
                "models": ["hermes-3"],
                "default_model": "hermes-3"
            },
            g4f.Provider.AutonomousAI: {
                "name": "Autonomous AI",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["llama-3.3-70b", "qwen-2.5-coder-32b", "hermes-3", "llama-3.2-90b"],
                "default_model": "llama-3.3-70b"
            },
            g4f.Provider.Blackbox: {
                "name": "Blackbox.ai",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["blackboxai", "gpt-4", "gpt-4o", "gemini-1.5-flash", "gemini-1.5-pro", 
                          "claude-3.5-sonnet", "blackboxai-pro", "llama-3.1-8b", "llama-3.1-70b",
                          "mixtral-7b", "deepseek-chat", "dbrx-instruct"],
                "default_model": "gpt-4"
            },
            g4f.Provider.CablyAI: {
                "name": "Cably AI",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["cably-80b"],
                "default_model": "cably-80b"
            },
            g4f.Provider.ChatGLM: {
                "name": "ChatGLM",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["glm-4"],
                "default_model": "glm-4"
            },
            g4f.Provider.ChatGpt: {
                "name": "ChatGPT",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-3.5-turbo"],
                "default_model": "gpt-3.5-turbo"
            },
            g4f.Provider.ChatGptEs: {
                "name": "ChatGPT ES",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-4", "gpt-4o", "gpt-4o-mini"],
                "default_model": "gpt-4"
            },
            g4f.Provider.ChatGptt: {
                "name": "ChatGPTT",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-4", "gpt-4o", "gpt-4o-mini"],
                "default_model": "gpt-4"
            },
            g4f.Provider.Cloudflare: {
                "name": "Cloudflare AI",
                "auth": ProviderCategory.AUTO_COOKIES,
                "models": ["llama-2-7b", "llama-3-8b", "llama-3.1-8b", "llama-3.2-1b", "qwen-1.5-7b"],
                "default_model": "llama-3.1-8b"
            },
            g4f.Provider.Copilot: {
                "name": "Copilot",
                "auth": ProviderCategory.OPTIONAL_API,
                "models": ["gpt-4", "gpt-4o"],
                "default_model": "gpt-4"
            },
            g4f.Provider.DarkAI: {
                "name": "Dark AI",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-3.5-turbo", "gpt-4o", "llama-3.1-70b"],
                "default_model": "gpt-4o"
            },
            g4f.Provider.DDG: {
                "name": "DuckDuckGo AI",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-4", "gpt-4o-mini", "claude-3-haiku", "llama-3.1-70b", "mixtral-8x7b"],
                "default_model": "gpt-4"
            },
            g4f.Provider.DeepInfraChat: {
                "name": "DeepInfra Chat",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["llama-3.1-8b", "llama-3.1-70b", "deepseek-chat", "qwen-2.5-72b"],
                "default_model": "llama-3.1-70b"
            },
            g4f.Provider.Free2GPT: {
                "name": "Free2GPT",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["mistral-7b"],
                "default_model": "mistral-7b"
            },
            g4f.Provider.FreeGpt: {
                "name": "FreeGPT",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gemini-1.5-pro"],
                "default_model": "gemini-1.5-pro"
            },
            g4f.Provider.GizAI: {
                "name": "Giz AI",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gemini-1.5-flash"],
                "default_model": "gemini-1.5-flash"
            },
            g4f.Provider.GPROChat: {
                "name": "GPRO Chat",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gemini-1.5-pro"],
                "default_model": "gemini-1.5-pro"
            },
            g4f.Provider.ImageLabs: {
                "name": "Image Labs",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gemini-1.5-pro"],
                "default_model": "gemini-1.5-pro"
            },
            g4f.Provider.HuggingSpace: {
                "name": "HuggingFace Space",
                "auth": ProviderCategory.OPTIONAL_API,
                "models": ["qvq-72b", "qwen-2-72b", "command-r", "command-r-plus", "command-r7b"],
                "default_model": "qwen-2-72b"
            },
            g4f.Provider.Jmuz: {
                "name": "Jmuz",
                "auth": ProviderCategory.OPTIONAL_API,
                "models": ["claude-3-haiku", "claude-3-opus", "claude-3.5-sonnet", "gemini-1.5-pro",
                          "gpt-4", "gpt-4o", "llama-3.3-70b", "mixtral-8x7b"],
                "default_model": "gpt-4"
            },
            g4f.Provider.Liaobots: {
                "name": "Liaobots",
                "auth": ProviderCategory.AUTO_COOKIES,
                "models": ["grok-2", "gpt-4o", "claude-3-opus", "gemini-1.5-pro", "claude-3.5-sonnet"],
                "default_model": "gpt-4o"
            },
            g4f.Provider.OIVSCode: {
                "name": "OI VSCode",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-4o-mini"],
                "default_model": "gpt-4o-mini"
            },
            g4f.Provider.PerplexityLabs: {
                "name": "Perplexity Labs",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["sonar-online", "sonar-chat", "llama-3.3-70b", "llama-3.1-8b"],
                "default_model": "sonar-chat"
            },
            g4f.Provider.Pi: {
                "name": "Pi AI",
                "auth": ProviderCategory.MANUAL_COOKIES,
                "models": ["pi"],
                "default_model": "pi"
            },
            g4f.Provider.Pizzagpt: {
                "name": "Pizza GPT",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-4o-mini"],
                "default_model": "gpt-4o-mini"
            },
            g4f.Provider.PollinationsAI: {
                "name": "Pollinations AI",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-4o-mini", "gpt-4o", "qwen-2.5-72b", "llama-3.3-70b", "deepseek-chat"],
                "default_model": "gpt-4o"
            },
            g4f.Provider.TeachAnything: {
                "name": "Teach Anything",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["llama-3.1-70b"],
                "default_model": "llama-3.1-70b"
            },
            g4f.Provider.You: {
                "name": "You.com",
                "auth": ProviderCategory.MANUAL_COOKIES,
                "models": ["gpt-3.5-turbo"],
                "default_model": "gpt-3.5-turbo"
            },
            g4f.Provider.Yqcloud: {
                "name": "YQ Cloud",
                "auth": ProviderCategory.NO_AUTH,
                "models": ["gpt-3.5-turbo"],
                "default_model": "gpt-3.5-turbo"
            }
        }
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
        self.providers = list(self.provider_info.keys())
        self.current_provider_index = 0
        self.last_used_provider = None

    async def get_ai_response(self, prompt: str) -> tuple[Optional[str], Optional[str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò —á–µ—Ä–µ–∑ g4f"""
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if self.last_used_provider and self.last_used_provider in self.providers:
            start_index = self.providers.index(self.last_used_provider)
            providers_list = self.providers[start_index:] + self.providers[:start_index]
        else:
            providers_list = self.providers

        tried_providers = []  # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —É–∂–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª–∏
        
        for provider in providers_list:
            if provider in tried_providers:
                continue
                
            tried_providers.append(provider)
            provider_info = self.provider_info[provider]
            model = provider_info["default_model"]
            
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É
                if hasattr(provider, 'create_async'):
                    try:
                        response = await asyncio.wait_for(
                            provider.create_async(
                                model=model,
                                messages=[{
                                    "role": "system",
                                    "content": "–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
                                }, {
                                    "role": "user",
                                    "content": prompt
                                }]
                            ),
                            timeout=30.0  # –¢–∞–π–º–∞—É—Ç 30 —Å–µ–∫—É–Ω–¥
                        )
                    except asyncio.TimeoutError:
                        continue
                else:
                    # –î–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º run_in_executor —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                    try:
                        response = await asyncio.wait_for(
                            asyncio.get_event_loop().run_in_executor(
                                None,
                                lambda: g4f.ChatCompletion.create(
                                    model=model,
                                    messages=[{
                                        "role": "system",
                                        "content": "–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
                                    }, {
                                        "role": "user",
                                        "content": prompt
                                    }],
                                    provider=provider
                                )
                            ),
                            timeout=30.0  # –¢–∞–π–º–∞—É—Ç 30 —Å–µ–∫—É–Ω–¥
                        )
                    except asyncio.TimeoutError:
                        continue

                if response and isinstance(response, str):
                    self.last_used_provider = provider
                    return response, provider_info["name"]
                    
            except Exception as e:
                continue
        
        # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–µ—Ä–µ–ø—Ä–æ–±–æ–≤–∞–Ω—ã –∏ –Ω–∏ –æ–¥–∏–Ω –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
        return None, None

    ai_group = app_commands.Group(name="ai", description="–ö–æ–º–∞–Ω–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ò–ò")

    @ai_group.command(name="ask", description="–°–ø—Ä–æ—Å–∏—Ç—å —á—Ç–æ-—Ç–æ —É –ò–ò")
    @app_commands.describe(–≤–æ–ø—Ä–æ—Å="–í–∞—à –≤–æ–ø—Ä–æ—Å –∫ –ò–ò")
    async def ai_ask(self, interaction: discord.Interaction, –≤–æ–ø—Ä–æ—Å: str):
        """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ò–ò"""
        await interaction.response.defer()
        
        response, provider_name = await self.get_ai_response(–≤–æ–ø—Ä–æ—Å)
        
        if response:
            embed=Embed(
                title=f"{self.AI_EMOJI} –û—Ç–≤–µ—Ç –ò–ò",
                description=response,
                color=0x2b2d31
            )
            
            embed.add_field(
                name="üìù –ó–∞–ø—Ä–æ—Å",
                value=f"{–≤–æ–ø—Ä–æ—Å[:1000]}{'...' if len(–≤–æ–ø—Ä–æ—Å) > 1000 else ''}",
                inline=False
            )
            
            if provider_name:
                embed.set_footer(text=f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä: {provider_name}")
            
            await interaction.followup.send(embed=embed)
        else:
            error_embed=Embed(
                title=f"{Emojis.ERROR} –û—à–∏–±–∫–∞",
                description="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò. –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                color=0xe74c3c
            )
            await interaction.followup.send(embed=error_embed)

    @ai_group.command(name="providers", description="–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –ò–ò")
    async def providers_list(self, interaction: discord.Interaction):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –ò–ò"""
        embeds = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–º–±–µ–¥–æ–≤
        current_embed=Embed(
            title=f"{self.AI_EMOJI} –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ò–ò (–ß–∞—Å—Ç—å 1)",
            color=0x2b2d31
        )
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–æ —Ç–∏–ø—É –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        providers_by_auth = {}
        for provider, info in self.provider_info.items():
            auth_type = info["auth"]
            if auth_type not in providers_by_auth:
                providers_by_auth[auth_type] = []
            
            status = "üü¢" if provider == self.last_used_provider else "‚ö™"
            # –°–æ–∫—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö
            models_str = ", ".join(info["models"][:2])
            if len(info["models"]) > 2:
                models_str += f" +{len(info['models'])-2}"
                
            provider_text = (
                f"{status} **{info['name']}** (`{info['default_model']}`)"
            )
            providers_by_auth[auth_type].append(provider_text)

        field_count = 0
        embed_count = 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤ —ç–º–±–µ–¥ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for auth_type in ProviderCategory:
            if auth_type in providers_by_auth:
                providers_text = "\n".join(providers_by_auth[auth_type])
                
                # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
                while len(providers_text) > 1024:
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–æ –ª–∏–º–∏—Ç–∞
                    split_index = providers_text.rfind("\n", 0, 1024)
                    if split_index == -1:
                        split_index = 1024
                    
                    current_embed.add_field(
                        name=f"üìÅ {auth_type.value}",
                        value=providers_text[:split_index],
                        inline=False
                    )
                    providers_text = providers_text[split_index:].strip()
                    field_count += 1
                    
                    # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞ –ø–æ–ª–µ–π –∏–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —á–∞—Å—Ç—å
                    if field_count >= 25 or len(providers_text) == 0:
                        embeds.append(current_embed)
                        embed_count += 1
                        current_embed=Embed(
                            title=f"{self.AI_EMOJI} –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ò–ò (–ß–∞—Å—Ç—å {embed_count})",
                            color=0x2b2d31
                        )
                        field_count = 0
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
                if providers_text:
                    current_embed.add_field(
                        name=f"üìÅ {auth_type.value}",
                        value=providers_text,
                        inline=False
                    )
                    field_count += 1
                    
                    # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞ –ø–æ–ª–µ–π
                    if field_count >= 25:
                        embeds.append(current_embed)
                        embed_count += 1
                        current_embed=Embed(
                            title=f"{self.AI_EMOJI} –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ò–ò (–ß–∞—Å—Ç—å {embed_count})",
                            color=0x2b2d31
                        )
                        field_count = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–º–±–µ–¥, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π
        if field_count > 0:
            embeds.append(current_embed)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ—É—Ç–µ—Ä –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —ç–º–±–µ–¥—É
        if embeds:
            embeds[-1].set_footer(text="üü¢ - –ü–æ—Å–ª–µ–¥–Ω–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π | ‚ö™ - –î–æ—Å—Ç—É–ø–Ω—ã–π")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —ç–º–±–µ–¥—ã
        for i, embed in enumerate(embeds):
            if i == 0:
                await interaction.response.send_message(embed=embed)
            else:
                await interaction.followup.send(embed=embed)

    @ai_group.command(name="info", description="–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–µ")
    @app_commands.describe(provider="–ò–º—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞")
    async def provider_info(self, interaction: discord.Interaction, provider: str):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–µ"""
        # –ò—â–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ –∏–º–µ–Ω–∏
        found_provider = None
        for p, info in self.provider_info.items():
            if info["name"].lower() == provider.lower():
                found_provider = (p, info)
                break
        
        if not found_provider:
            await interaction.response.send_message(
                embed=Embed(
                    title=f"{Emojis.ERROR} –û—à–∏–±–∫–∞",
                    description=f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä '{provider}' –Ω–µ –Ω–∞–π–¥–µ–Ω",
                    color=0xe74c3c
                ),
                ephemeral=True
            )
            return
        
        provider_class, info = found_provider
        embed=Embed(
            title=f"{self.AI_EMOJI} –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–µ {info['name']}",
            color=0x2b2d31
        )
        
        embed.add_field(
            name="üîë –¢–∏–ø –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏",
            value=info["auth"].value,
            inline=False
        )
        
        embed.add_field(
            name="üìö –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏",
            value="\n".join([f"‚Ä¢ {model}" for model in info["models"]]),
            inline=False
        )
        
        embed.add_field(
            name="‚≠ê –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é",
            value=f"`{info['default_model']}`",
            inline=False
        )
        
        if provider_class == self.last_used_provider:
            embed.add_field(
                name="üìä –°—Ç–∞—Ç—É—Å",
                value="üü¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä",
                inline=False
            )
        
        await interaction.response.send_message(embed=embed)

async def setup(bot):
    await bot.add_cog(AI(bot)) 